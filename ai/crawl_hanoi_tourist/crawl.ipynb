{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Crawling page 1...\n",
      "https://hanoitourist.vn/can-tho-soc-trang-con-dao\n",
      "âœ… Cáº¦N THÆ  - SÃ“C TRÄ‚NG - CÃ”N Äáº¢O\n",
      "ğŸ“ NgÃ y Ä‘i: 19/04, 17/05, 20/06/2025... (4 ngÃ y 3 Ä‘Ãªm) | ğŸ“… HÃ nh trÃ¬nh: TP. Há»“ ChÃ­ Minh - Cáº§n ThÆ¡ - CÃ´n Äáº£o - 4 ngÃ y 3 Ä‘Ãªm | ğŸ’° 8,790,000Ä‘\n",
      "ğŸ“ Lá»‹ch trÃ¬nh: NGÃ€Y 01: HÃ€ Ná»˜I - Cáº¦N THÆ  - SÃ“C TRÄ‚NG (Ä‚N Tá»I)\n",
      "NGÃ€Y 02: SÃ“C TRÄ‚NG - CÃ”N Äáº¢O (Ä‚N TRÆ¯A, Tá»I)\n",
      "NGÃ€Y 03: ...\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "https://hanoitourist.vn/can-tho-cao-lanh-chau-doc-giang-can-tho\n",
      "âœ… Cáº¦N THÆ  - CAO LÃƒNH - CHÃ‚U Äá»C - AN GIANG - Cáº¦N THÆ \n",
      "ğŸ“ NgÃ y Ä‘i: 19/04, 17/05, 20/06/2025... (4 ngÃ y 3 Ä‘Ãªm) | ğŸ“… HÃ nh trÃ¬nh: Cáº§n ThÆ¡ - TP. Há»“ ChÃ­ Minh - 4 ngÃ y 3 Ä‘Ãªm | ğŸ’° 8,150,000Ä‘\n",
      "ğŸ“ Lá»‹ch trÃ¬nh: NGÃ€Y 1: HÃ€ Ná»˜I - Cáº¦N THÆ  - CAO LÃƒNH (Ä‚n tá»‘i)\n",
      "NGÃ€Y 2: CAO LÃƒNH - TRI TÃ”N - Rá»ªNG TRÃ€M - CHÃ‚U Äá»C (Ä‚n s...\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "https://hanoitourist.vn/vinwonder-bai-tranh-lang-chai-vinh-san-ho-dong-cuu-hang-rai-vuon-nho-ninh-thuan-thap-ba-ponagar-tam\n",
      "âœ… VINWONDER â€“ BÃƒI TRANH â€“ LÃ€NG CHÃ€I â€“ Vá»ŠNH SAN HÃ” Äá»’NG Cá»ªU â€“ HANG RÃI - VÆ¯á»œN NHO NINH THUáº¬N THÃP BÃ€ PONAGAR â€“ Táº®M BÃ™N Iâ€™RESORT\n",
      "ğŸ“ NgÃ y Ä‘i: 21/04, 18/05, 20/05/2025... (4 ngÃ y 3 Ä‘Ãªm) | ğŸ“… HÃ nh trÃ¬nh: Nha Trang - 4 ngÃ y 3 Ä‘Ãªm | ğŸ’° 5,990,000Ä‘\n",
      "ğŸ“ Lá»‹ch trÃ¬nh: NGÃ€Y 1: HÃ€ Ná»˜I â€“ NHA TRANG â€“ CHÃ™A LONG SÆ N (Ä‚N Tá»I)\n",
      "NGÃ€Y 2: VUI CHÆ I VINPEARL NHA TRANG (Ä‚N SÃNG, Tá»...\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "https://hanoitourist.vn/can-tho-soc-trang-bac-lieu-ca-mau-dat-mui-tien-giang-ben-tre-tay-ninh-sai-gon\n",
      "âœ… Cáº¦N THÆ  â€“ SÃ“C TRÄ‚NG â€“ Báº C LIÃŠU CÃ€ MAU â€“ Äáº¤T MÅ¨I â€“ TIá»€N GIANG â€“ Báº¾N TRE -TÃ‚Y NINH â€“ SÃ€I GÃ’N\n",
      "ğŸ“ NgÃ y Ä‘i: 22/04, 24/04, 11/05/2025... (5 ngÃ y 4 Ä‘Ãªm) | ğŸ“… HÃ nh trÃ¬nh: TP. Há»“ ChÃ­ Minh - Cáº§n ThÆ¡ - 5 ngÃ y 4 Ä‘Ãªm | ğŸ’° 9,490,000Ä‘\n",
      "ğŸ“ Lá»‹ch trÃ¬nh: NGÃ€Y 1: HÃ€ Ná»˜I â€“ Cáº¦N THÆ  â€“ CÃ€ MAU (Ä‚n trÆ°a, tá»‘i)\n",
      "NGÃ€Y 2: CÃ€ MAU â€“ Äáº¤T MÅ¨I â€“ Cáº¦N THÆ  (Ä‚N SÃNG, TRÆ¯A, ...\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "https://hanoitourist.vn/tra-linh-tp-tinh-tay-nga-tuyen-pho-co-cam-tu-co-long-dai-hiep-coc-hang-pac-bo-thac-ban-gioc\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import aiohttp\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def download_image(session, url, filename):\n",
    "    async with session.get(url) as resp:\n",
    "        if resp.status == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(await resp.read())\n",
    "\n",
    "async def crawl_tour_detail(context, detail_url):\n",
    "    page = await context.new_page()\n",
    "    await page.goto(detail_url)\n",
    "    await page.wait_for_timeout(3000)\n",
    "\n",
    "    try:\n",
    "        itinerary_buttons = await page.locator(\"button.accordion-button\").all()\n",
    "        itinerary = \"\\n\".join([await btn.inner_text() for btn in itinerary_buttons])\n",
    "        \n",
    "\n",
    "    except:\n",
    "        itinerary = \"KhÃ´ng cÃ³ dá»¯ liá»‡u lá»‹ch trÃ¬nh\"\n",
    "\n",
    "    try:\n",
    "        includes = await page.locator(\"div.includes\").inner_text()\n",
    "    except:\n",
    "        includes = \"KhÃ´ng rÃµ dá»‹ch vá»¥ bao gá»“m\"\n",
    "\n",
    "    await page.close()\n",
    "    return {\n",
    "        \"itinerary\": itinerary,\n",
    "        \"includes\": includes\n",
    "    }\n",
    "\n",
    "async def crawl_tours():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "        base_url = \"https://hanoitourist.vn/tour-trong-nuoc\"\n",
    "        await page.goto(base_url)\n",
    "        await page.wait_for_timeout(5000)\n",
    "\n",
    "        current_page = 1\n",
    "        max_page = 1  # Äá»•i sá»‘ trang muá»‘n crawl táº¡i Ä‘Ã¢y\n",
    "\n",
    "        all_tours = []\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            while current_page <= max_page:\n",
    "                print(f\"ğŸ” Crawling page {current_page}...\")\n",
    "\n",
    "                tour_cards = await page.locator(\"div.tour-item\").all()\n",
    "\n",
    "                for i, card in enumerate(tour_cards):\n",
    "                    try:\n",
    "                        title = await card.locator(\"h3 a\").inner_text()\n",
    "                        price = await card.locator(\"div.detail-gia\").inner_text()\n",
    "                        location = await card.locator(\"div.detail-item-value >> nth=1\").inner_text()\n",
    "                        dates = await card.locator(\"div.detail-item-value >> nth=0\").inner_text()\n",
    "                        detail_url = await card.locator(\"h3 a\").get_attribute(\"href\")\n",
    "                        full_detail_url = f\"https://hanoitourist.vn{detail_url}\" if detail_url.startswith(\"/\") else detail_url\n",
    "                        print(full_detail_url)\n",
    "                        image_url = await card.locator(\"div.tour-img img\").get_attribute(\"src\")\n",
    "                        filename = f\"tour_image_{current_page}_{i+1}.jpg\"\n",
    "\n",
    "                        # if image_url:\n",
    "                        #     await download_image(session, image_url, filename)\n",
    "\n",
    "                        # Crawl chi tiáº¿t tá»«ng tour\n",
    "                        detail_data = await crawl_tour_detail(context, full_detail_url)\n",
    "\n",
    "                        tour_info = {\n",
    "                            \"title\": title,\n",
    "                            \"location\": location,\n",
    "                            \"dates\": dates,\n",
    "                            \"price\": price,\n",
    "                            \"image_url\": image_url,\n",
    "                            \"detail_url\": full_detail_url,\n",
    "                            **detail_data\n",
    "                        }\n",
    "\n",
    "                        print(f\"âœ… {title}\")\n",
    "                        print(f\"ğŸ“ {location} | ğŸ“… {dates} | ğŸ’° {price}\")\n",
    "                        print(f\"ğŸ“ Lá»‹ch trÃ¬nh: {detail_data['itinerary'][:100]}...\")\n",
    "                        print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "\n",
    "                        all_tours.append(tour_info)\n",
    "                    except Exception as e:\n",
    "                        print(\"âš ï¸ Lá»—i xá»­ lÃ½ card:\", e)\n",
    "\n",
    "                # TÃ¬m nÃºt \"Trang tiáº¿p\" Ä‘á»ƒ next page\n",
    "                try:\n",
    "                    next_btn = page.locator(\"a.page-link:has-text('>')\")\n",
    "                    if await next_btn.is_visible():\n",
    "                        await next_btn.click()\n",
    "                        await page.wait_for_timeout(3000)\n",
    "                        current_page += 1\n",
    "                    else:\n",
    "                        break\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "        print(f\"ğŸ‰ Tá»•ng cá»™ng thu Ä‘Æ°á»£c {len(all_tours)} tour.\")\n",
    "        \n",
    "        # CÃ³ thá»ƒ lÆ°u `all_tours` vÃ o file CSV hoáº·c JSON náº¿u muá»‘n.\n",
    "\n",
    "# Cháº¡y\n",
    "await crawl_tours()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def crawl_tripadvisor_carousel_images_updated(url, num_clicks=10):\n",
    "    from playwright.async_api import async_playwright\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    from urllib.parse import urljoin\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)  # Debug báº±ng browser tháº­t\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url)\n",
    "        await page.wait_for_timeout(3000)\n",
    "\n",
    "        # Scroll Ä‘á»ƒ hiá»‡n carousel\n",
    "        await page.evaluate(\"window.scrollBy(0, 1000)\")\n",
    "        await page.wait_for_timeout(2000)\n",
    "\n",
    "        # Click mÅ©i tÃªn pháº£i nhiá»u láº§n\n",
    "        for i in range(num_clicks):\n",
    "            try:\n",
    "                next_btn = page.locator('button.pWJww')\n",
    "                if await next_btn.is_visible():\n",
    "                    await next_btn.click()\n",
    "                    await page.wait_for_timeout(800)\n",
    "                else:\n",
    "                    print(f\"[{i}] KhÃ´ng tháº¥y nÃºt next.\")\n",
    "            except Exception as e:\n",
    "                print(f\"[{i}] âŒ KhÃ´ng báº¥m Ä‘Æ°á»£c: {e}\")\n",
    "                break\n",
    "\n",
    "        html = await page.content()\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        image_urls = set()\n",
    "\n",
    "        # âœ… QuÃ©t táº¥t cáº£ div chá»©a áº£nh: ZGLUM lÃ  container\n",
    "        for container in soup.select(\"div.ZGLUM\"):\n",
    "            for img in container.select(\"img\"):\n",
    "                src = img.get(\"src\") or img.get(\"data-src\") or \"\"\n",
    "                if not src:\n",
    "                    continue\n",
    "                src = re.sub(r\"-s\\d+x\\d+\", \"-s1600x1200\", src).split(\"?\")[0]\n",
    "                if not src.startswith(\"http\"):\n",
    "                    src = urljoin(\"https://www.tripadvisor.com\", src)\n",
    "                if \"icons\" in src.lower():\n",
    "                    continue\n",
    "                image_urls.add(src)\n",
    "\n",
    "            # âœ… Náº¿u cÃ³ tháº» <source> (áº£nh responsive)\n",
    "            for source in container.select(\"source\"):\n",
    "                srcset = source.get(\"srcset\", \"\")\n",
    "                for part in srcset.split(\",\"):\n",
    "                    candidate = part.strip().split(\" \")[0]\n",
    "                    candidate = re.sub(r\"-s\\d+x\\d+\", \"-s1600x1200\", candidate).split(\"?\")[0]\n",
    "                    if candidate.startswith(\"http\"):\n",
    "                        image_urls.add(candidate)\n",
    "\n",
    "        await browser.close()\n",
    "        return list(image_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] KhÃ´ng tháº¥y nÃºt next.\n",
      "[1] KhÃ´ng tháº¥y nÃºt next.\n",
      "[2] KhÃ´ng tháº¥y nÃºt next.\n",
      "[3] KhÃ´ng tháº¥y nÃºt next.\n",
      "[4] KhÃ´ng tháº¥y nÃºt next.\n",
      "[5] KhÃ´ng tháº¥y nÃºt next.\n",
      "[6] KhÃ´ng tháº¥y nÃºt next.\n",
      "[7] KhÃ´ng tháº¥y nÃºt next.\n",
      "[8] KhÃ´ng tháº¥y nÃºt next.\n",
      "[9] KhÃ´ng tháº¥y nÃºt next.\n",
      "[10] KhÃ´ng tháº¥y nÃºt next.\n",
      "[11] KhÃ´ng tháº¥y nÃºt next.\n",
      "[12] KhÃ´ng tháº¥y nÃºt next.\n",
      "[13] KhÃ´ng tháº¥y nÃºt next.\n",
      "[14] KhÃ´ng tháº¥y nÃºt next.\n",
      "[15] KhÃ´ng tháº¥y nÃºt next.\n",
      "[16] KhÃ´ng tháº¥y nÃºt next.\n",
      "[17] KhÃ´ng tháº¥y nÃºt next.\n",
      "[18] KhÃ´ng tháº¥y nÃºt next.\n",
      "[19] KhÃ´ng tháº¥y nÃºt next.\n",
      "ğŸ‰ TÃ¬m Ä‘Æ°á»£c 4 áº£nh:\n",
      "https://dynamic-media-cdn.tripadvisor.com/media/photo-o/2f/9b/57/24/caption.jpg\n",
      "https://dynamic-media-cdn.tripadvisor.com/media/photo-o/09/32/1d/c4/old-quarter.jpg\n",
      "https://dynamic-media-cdn.tripadvisor.com/media/photo-o/2f/9c/23/45/caption.jpg\n",
      "https://dynamic-media-cdn.tripadvisor.com/media/photo-o/2f/9b/57/23/caption.jpg\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "url = \"https://www.tripadvisor.com/Attraction_Review-g293924-d317503-Reviews-Old_Quarter-Hanoi.html\"\n",
    "imgs = await crawl_tripadvisor_carousel_images_updated(url, num_clicks=20)\n",
    "\n",
    "print(f\"ğŸ‰ TÃ¬m Ä‘Æ°á»£c {len(imgs)} áº£nh:\")\n",
    "for img in imgs[:10]:\n",
    "    print(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 49\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcrawl_foody_hanoi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpages_to_crawl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     51\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfoody_hanoi.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36mcrawl_foody_hanoi\u001b[0;34m(pages_to_crawl)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrawl_foody_hanoi\u001b[39m(pages_to_crawl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      8\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msync_playwright\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchromium\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheadless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/playwright/sync_api/_context_manager.py:47\u001b[0m, in \u001b[0;36mPlaywrightContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_own_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m---> 47\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Error(\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"It looks like you are using Playwright Sync API inside the asyncio loop.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03mPlease use the Async API instead.\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m             )\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;66;03m# Create a new fiber for the protocol dispatcher. It will be pumping events\u001b[39;00m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;66;03m# until the end of times. We will pass control to that fiber every time we\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;66;03m# block while waiting for a response.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreenlet_main\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mError\u001b[0m: It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead."
     ]
    }
   ],
   "source": [
    "# crawl_foody_hanoi.py\n",
    "\n",
    "from playwright.sync_api import sync_playwright\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def crawl_foody_hanoi(pages_to_crawl=3):\n",
    "    results = []\n",
    "\n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "        page = browser.new_page()\n",
    "        base_url = \"https://www.foody.vn/ha-noi/dia-diem?page=\"\n",
    "\n",
    "        for i in range(1, pages_to_crawl + 1):\n",
    "            print(f\"Crawling page {i}...\")\n",
    "            page.goto(base_url + str(i), timeout=60000)\n",
    "            page.wait_for_timeout(5000)\n",
    "\n",
    "            items = page.query_selector_all(\"div.result-group > div[data-view-id]\")\n",
    "            for item in items:\n",
    "                try:\n",
    "                    name = item.query_selector(\"h2 > a\").inner_text().strip()\n",
    "                    url = item.query_selector(\"h2 > a\").get_attribute(\"href\")\n",
    "                    full_url = \"https://www.foody.vn\" + url\n",
    "\n",
    "                    address = item.query_selector(\".result-address\").inner_text().strip()\n",
    "                    rating = item.query_selector(\".point.highlight\").inner_text().strip() if item.query_selector(\".point.highlight\") else \"N/A\"\n",
    "                    category = item.query_selector(\".detail-info\").inner_text().strip() if item.query_selector(\".detail-info\") else \"N/A\"\n",
    "                    img_url = item.query_selector(\"img\").get_attribute(\"src\")\n",
    "\n",
    "                    results.append({\n",
    "                        \"TÃªn\": name,\n",
    "                        \"Äá»‹a chá»‰\": address,\n",
    "                        \"Äiá»ƒm\": rating,\n",
    "                        \"Loáº¡i hÃ¬nh\": category,\n",
    "                        \"Link áº£nh\": img_url,\n",
    "                        \"Foody URL\": full_url\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Error on item: {e}\")\n",
    "                    continue\n",
    "\n",
    "        browser.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = crawl_foody_hanoi(pages_to_crawl=5)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"foody_hanoi.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"âœ… ÄÃ£ lÆ°u káº¿t quáº£ vÃ o foody_hanoi.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
